<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="./style.css" />
    <title>Нейромережі</title>
  </head>
  <body>
    <div class="title"><h1 class="text-center">Нейромережі</h1></div>
    <div class="content-container">
      <div class="seperator" />
      <div class="center-y">
        <img
          class="img-no-bg"
          src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Multi-Layer_Neural_Network-Vector-Blank.svg/800px-Multi-Layer_Neural_Network-Vector-Blank.svg.png" />
      </div>
      <span class="seperator content">
        Нейромережі - це обчислювальні системи, натхнені біологічними нейронними мережами, що складають мозок тварин. Такі системи
        навчаються задач, розглядаючи приклади, загалом без спеціального програмування під задачу. Наприклад, у розпізнаванні
        зображень вони можуть навчатися ідентифікувати зображення, які містять котів, аналізуючи приклади зображень, мічені як
        «кіт» і «не кіт», і використовуючи результати для ідентифікування котів в інших зображеннях.
        <br />
        <div class="seperator"></div>
        <div class="center-y">
          <img src="https://cdn.discordapp.com/attachments/678562111428886548/1046485279155966134/image.png" />
        </div>
        <div class="seperator"></div>
        Вони роблять це без жодного апріорного знання про котів, наприклад, що вони мають хутро, хвости, вуса та котоподібні
        писки. Натомість, вони розвивають свій власний набір доречних характеристик з навчального матеріалу, який вони оброблюють.
      </span>
      <div class="title"><h1 class="text-center">Використання нейромереж у сучасному світі</h1></div>
      <span class="seperator content">
        Через свою здатність відтворювати та моделювати нелінійні процеси, нейромережі знайшли застосування в широкому діапазоні
        дисциплін.
        <br />
        <br />
        До областей застосування належать ідентифікація систем та керування (керування транспортними засобами, передбачування
        траєкторії, автоматизація виробничих процесів), квантова хімія, гра в ігри та ухвалювання рішень (короткі нарди, шахи,
        покер), розпізнавання образів (радарні системи, ідентифікація облич, класифікація сигналів, розпізнавання об'єктів та
        ін.), розпізнавання послідовностей (жестів, мовлення, рукописного тексту), медична діагностика, фінанси (наприклад,
        автоматизовані системи торгівлі), добування даних, машинний переклад, соціально-мережеве фільтрування та фільтрування
        спаму електронної пошти.
        <br />
        <div class="seperator"></div>
        <div class="center-y">
          <img
            src="https://images.ctfassets.net/3viuren4us1n/5YzA7KGIWQEjt8KStZGlxd/85bde9966a9e9c4407396f424e46fc67/facial_recognition.jpg" />
        </div>
        <div class="seperator"></div>
        Нейронні мережі застосовували в діагностуванні раку, а також щоби відрізняти лінії ракових клітин, сильно схильні до
        розповсюдження, від менш схильних до розповсюдження ліній, із застосуванням лише інформації про форму клітин.
      </span>
      <div class="title"><h1 class="text-center">Моделі</h1></div>
      <span class="seperator content">
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D1%83%D0%BF%D0%BE%D0%B2%D0%BE%D0%B3%D0%BE_%D1%83%D1%80%D0%B0%D1%85%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B0%D1%80%D0%B3%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%96%D0%B2">
          Метод групового урахування аргументів
        </a>
        - демонструє повністю автоматичну структурну та параметричну оптимізацію моделей. Функціями збудження вузлів є поліноми
        Колмогорова — Габора, що дозволяють додавання та множення. Він використовує глибинний багатошаровий перцептрон прямого
        поширення з вісьмома шарами.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%97%D0%B3%D0%BE%D1%80%D1%82%D0%BA%D0%BE%D0%B2%D1%96_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%96_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D1%96">
          Згорткові нейронні мережі
        </a>
        - це клас глибинних мереж прямого поширення, складених з одного чи більше згорткових шарів, із повноз'єднаними шарами на
        верхівці. Він використовує зв'язані ваги та шари агрегування. Зокрема, за згортковою архітектурою Фукусіми часто
        зорганізовують максимізаційне агрегування.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%94%D0%BE%D0%B2%D0%B3%D0%B0_%D0%BA%D0%BE%D1%80%D0%BE%D1%82%D0%BA%D0%BE%D1%87%D0%B0%D1%81%D0%BD%D0%B0_%D0%BF%D0%B0%D0%BC'%D1%8F%D1%82%D1%8C">
          Довга короткочасна пам'ять
        </a>
        - це мережі, які уникають проблеми зникання градієнту. ДКЧП зазвичай доповнювано рекурентними вентилями, які називають
        забувальними. Мережі ДКЧП запобігають зниканню та вибуханню зворотно поширюваних похибок. Натомість, похибки можуть
        плинути в зворотному напрямку необмеженим числом віртуальних шарів розгорнутої в просторі ДКЧП.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%93%D0%BB%D0%B8%D0%B1%D0%B8%D0%BD%D0%BD%D0%B5_%D1%80%D0%B5%D0%B7%D0%B5%D1%80%D0%B2%D1%83%D0%B0%D1%80%D0%BD%D0%B5_%D0%BE%D0%B1%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F">
          Глибинне резервуарне обчислення
        </a>
        та глибинні мережі з відлунням стану забезпечують систему для ефективного тренування моделей для ієрархічної обробки
        часових даних, в той же час уможливлюючи дослідження властивої ролі шаруватого компонування.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%93%D0%BB%D0%B8%D0%B1%D0%B8%D0%BD%D0%BD%D1%96_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D1%96_%D0%BF%D0%B5%D1%80%D0%B5%D0%BA%D0%BE%D0%BD%D0%B0%D0%BD%D1%8C">
          Глибинні мережі переконань
        </a>
        - це ймовірнісна породжувальна модель, складена з декількох шарів прихованих вузлів. Її можна розглядати як композицію
        простих модулів навчання, що складають кожен з шарів.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%96_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D1%96_%D0%B7%D0%B1%D0%B5%D1%80%D1%96%D0%B3%D0%B0%D0%BD%D0%BD%D1%8F_%D1%82%D0%B0_%D0%B2%D0%B8%D0%B1%D1%96%D1%80%D0%BA%D0%B8_%D0%B2%D0%B5%D0%BB%D0%B8%D0%BA%D0%BE%D1%97_%D0%BF%D0%B0%D0%BC'%D1%8F%D1%82%D1%96">
          Нейронні мережі зберігання та вибірки великої пам'яті
        </a>
        та вибірки великої пам'яті є швидкими нейронними мережами глибинного навчання з багатьма шарами, які можуть
        використовувати багато фільтрів одночасно. Ці фільтри можуть бути нелінійними, стохастичними, логічними, не стаціонарними
        та навіть не аналітичними. Вони є біологічно натхненними, і навчаються безперервно.
        <br />
        <br />
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%93%D0%BB%D0%B8%D0%B1%D0%B8%D0%BD%D0%BD%D1%96_%D1%81%D0%BA%D0%BB%D0%B0%D0%B4%D0%B0%D0%BB%D1%8C%D0%BD%D1%96_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D1%96">
          Глибинні складальні мережі
        </a>
        - ґрунтується на ієрархії блоків спрощених нейромережевих модулів. Її було представлено 2011 року Деном та Доном. Вона
        формулює навчання як задачу опуклої оптимізації з розв'язком замкненого вигляду, підкреслюючи подібність цього механізму
        до складеного узагальнення. Кожен блок ГСМ є простим модулем, який легко тренувати сам по собі керованим чином без
        зворотного поширення для всіх блоків.
        <br />
        <br />
        Та
        <a
          href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0#%D0%92%D0%B0%D1%80%D1%96%D0%B0%D0%BD%D1%82%D0%B8">
          інші.
        </a>
      </span>
      <div class="title"><h1 class="text-center">Джерела та автор</h1></div>
      <span class="seperator content">
        Виконав студент групи 2КН-22Б, Павлов Ярослав, використавши такі джерела: <a href="https://wikipedia.org">Wikipedia</a>,
        <a href="https://images.google.com">Google Images</a>.
      </span>
    </div>
  </body>
</html>
